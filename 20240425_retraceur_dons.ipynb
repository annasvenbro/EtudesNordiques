{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMROIg8OPjNVnTibtQjYoUD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annasvenbro/etudesnordiques/blob/main/20240425_retraceur_dons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Outil pour retracer les dons tels que signalés dans le Sudoc"
      ],
      "metadata": {
        "id": "_MORn1LCdHaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On cherche à faire un *dataframe* de documents issu des dons au sein d'une bibliothèque donnée à partir de l'interrogation de l'index RPC du Sudoc, avec :\n",
        "*   le PPN ;\n",
        "*   le titre ;\n",
        "*   l'auteur ;\n",
        "*   les données d'exemplaire ;\n",
        "*   les données de provenance ;\n",
        "*   les donateurs / possesseurs ;\n",
        "*   la cote.\n",
        "\n",
        "On va donc :\n",
        "*   interroger l'API SRU du Sudoc ;\n",
        "*   extraire le contenu des balises XML pertinentes ;\n",
        "*   présenter le résultat sous forme de *dataframe*."
      ],
      "metadata": {
        "id": "j7uDC23xdNj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import des paquets nécessaires"
      ],
      "metadata": {
        "id": "Yulm8zBEeM5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests as rq\n",
        "import xml.etree.ElementTree as et\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ipywidgets as widgets\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "1wg2Hk7qeMmL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Création du menu déroulant avec les bibliothèques du réseau Sudoc"
      ],
      "metadata": {
        "id": "9-GdNBFMdSu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "liste_rcr=rq.get(\"https://www.idref.fr/services/listrcr\") #On requête l'URL du webservice.\n",
        "liste_rcr_text=liste_rcr.text #On voit la tête de la réponse.\n",
        "lines=liste_rcr_text.split(\"\\n\")#Transformation de la réponse en tableau.\n",
        "header=lines[0].split(\"\\t\")\n",
        "header[0]=header[0].strip(\"\\ufeff\") #Pour ne pas avoir de bug dans le dataframe final avec les BOM.\n",
        "data=[line.split(\"\\t\") for line in lines[1:] if line]\n",
        "df_rcr=pd.DataFrame(data,columns=header) #Transformation en dataframe.\n",
        "df_rcr.columns=df_rcr.columns.str.strip(\"\\ufeff\") #Nettoyage du dataframe (BOM, signe égal, guillemets et autres caractères parasites).\n",
        "df_rcr[\"RCR\"]=df_rcr[\"RCR\"].str.replace(\"=\",\"\")\n",
        "df_rcr[\"RCR\"]=df_rcr[\"RCR\"].str.replace('\"','')\n",
        "df_rcr=df_rcr.filter(regex='^RCR$|^LIBELLE$')#Sinon on a un bug à cause des BOM.\n",
        "df_rcr"
      ],
      "metadata": {
        "id": "EQfWm5YBdcFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rcr_input=None\n",
        "def nom2rcr(change): #Définition de la fonction pour avoir accès au RCR.\n",
        "    global rcr_input\n",
        "    selec_rcr=change[\"new\"]  #Bibliothèque sélectionnée dans le menu déroulant\n",
        "    rcr_input=df_rcr.loc[df_rcr[\"LIBELLE\"]==selec_rcr,\"RCR\"].iloc[0]"
      ],
      "metadata": {
        "id": "ZH_cnsiUeMk9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texte_autocomplet = widgets.Text(placeholder=\"Saisir le nom de la bibliothèque\") #Création de la fenâtre de saisie pour l'autocomplétion.\n",
        "\n",
        "liste_bib=widgets.Dropdown(\n",
        "    options=df_rcr[\"LIBELLE\"],  #Les options du menu déroulant sont les éléments de la colonne \"LIBELLE\".\n",
        "    description=\"Nom de la bibliothèque :\"\n",
        ")\n",
        "def update_options(change):\n",
        "    filtered_options = [option for option in df_rcr[\"LIBELLE\"] if texte_autocomplet.value.lower() in option.lower()]\n",
        "    liste_bib.options = filtered_options\n",
        "\n",
        "texte_autocomplet.observe(update_options, \"value\")\n",
        "\n",
        "display(texte_autocomplet)# Afficher les widgets.\n",
        "display(liste_bib)"
      ],
      "metadata": {
        "id": "pkmhSrdzeSSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "liste_bib.observe(nom2rcr,names=\"value\") #Sélection de la bibliothèque choisie dans le menu déroulant.\n",
        "print(rcr_input) #Vérification de l'enreigstrment de la variable (pas très stable)."
      ],
      "metadata": {
        "id": "aJ6ac9dVeTGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Requête de l'API SRU du Sudoc grâce à l'index RPC et avec la limitation du RCR choisi."
      ],
      "metadata": {
        "id": "jkXrRXYpd-8o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Création de la variable concernant la provenance"
      ],
      "metadata": {
        "id": "rqN1mgcfgg9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rpc_input=input(\"Entrez le nom à partir duquel vous voulez rechercher des données de provenance :\") #Saisie de la donnée de provenance à analyser."
      ],
      "metadata": {
        "id": "-IXqpT2Egshm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Parsage du flux XML obtenu"
      ],
      "metadata": {
        "id": "ESL3pOz9fVju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ppn(rcr_input,rpc_input):\n",
        "    liste_ppn=[]  # On initialise la liste des PPN.\n",
        "    start_token=1  # On paramètre le token de départ.\n",
        "    step=500  # On définit le pas de l'incrément.\n",
        "    req_nb_notices=rq.get(f\"https://www.sudoc.abes.fr/cbs/sru/?operation=searchRetrieve&version=1.1&recordSchema=unimarc&query=rpc%3D{rpc_input}%20and%20rbc%3D{rcr_input}\")\n",
        "    root_nb_notices=et.fromstring(req_nb_notices.content)\n",
        "    notices = int(root_nb_notices.find('.//{http://www.loc.gov/zing/srw/}numberOfRecords').text) # On requête l'API une première fois pour obtenir le nombre total de notices.\n",
        "    end_token=((notices-1)//step+1)*step # On paramètre le dernier token pour le tronquer à la 500-aine précédant la valeur totale du nombre d'enregistrements.\n",
        "    for token in range(start_token, end_token + 1, step): # On fait la requête avec le token pour récupérer les enregistrements.\n",
        "        req=rq.get(f\"https://www.sudoc.abes.fr/cbs/sru/?operation=searchRetrieve&version=1.1&recordSchema=unimarc&maximumRecords=500&startRecord={str(token)}&query=rpc%3D{rpc_input}%20and%20rbc%3D{rcr_input}\")\n",
        "        root_sudoc=et.fromstring(req.content)\n",
        "        for record in root_sudoc.findall('.//{http://www.loc.gov/zing/srw/}record'):# On trouve la balise du PPN.\n",
        "          controlfield_003=record.find('.//controlfield[@tag=\"003\"]')\n",
        "          #if controlfield_003 is not None:\n",
        "          #  datafield_trad=record.find('.//datafield[@tag=\"101\"]/subfield[@code=\"c\"]') # On sélectionne les PPN qui ont une zone 101$c\n",
        "          #  if datafield_trad is not None and datafield_trad.text==langue: #On sélectionne les PPN sont la 101$c est égale à celle de la langue choisie.\n",
        "          liste_ppn.append(controlfield_003.text)\n",
        "          liste_ppn=[url.replace(\"http://\", \"https://\") for url in liste_ppn]\n",
        "    return liste_ppn"
      ],
      "metadata": {
        "id": "zidmRd-xheTT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "liste_ppn=get_ppn(rcr_input,rpc_input) #Obtention de la liste des PPN concernés par la provenance.\n",
        "liste_ppn"
      ],
      "metadata": {
        "id": "y1e4RGqQknQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(liste_ppn) #Longueur de la liste des PPN obtenue."
      ],
      "metadata": {
        "id": "lyvsRbzXiTi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Création du *dataframe*"
      ],
      "metadata": {
        "id": "ow7ruW7ylKZ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On veut, pour une liste de PPN d'un RCR donné, créer un *dataframe* avec les informations concernant chaque document de la liste, avec son PPN (003), son type (008), son titre (200\\$a), ses auteurs (200\\$f), son éditeur (210\\$c ou 214\\$c), sa date (210\\$c ou 214\\$d), ses notes d'exemplaires (316\\$a), sa provenance(317\\$a), sa cote (930\\$a)."
      ],
      "metadata": {
        "id": "iWse5vhrk6eT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Création de la fonction d'extraction des données"
      ],
      "metadata": {
        "id": "f9pcTRNVlZnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_item(ppn):\n",
        "  req_item=rq.get(f\"{ppn}.xml\")\n",
        "  root_item=et.fromstring(req_item.content) #On requête le flux XML associé au PPN.\n",
        "\n",
        "  if root_item.find(\".//controlfield[@tag='008']\") is not None: #On extrait le type de document selon la nomenclature de l'Abes.\n",
        "    controlfield_008=root_item.find(\".//controlfield[@tag='008']\")\n",
        "  else: controlfield_008=None\n",
        "  type_code=controlfield_008.text if controlfield_008 is not None else \"\"\n",
        "  if type_code.startswith(\"Aa\"):\n",
        "    type_doc=\"Monographie imprimée\"\n",
        "  elif type_code.startswith(\"Ab\"):\n",
        "    type_doc=\"Périodique imprimé\"\n",
        "  elif type_code.startswith(\"Ad\"):\n",
        "    type_doc=\"Collection imprimée\"\n",
        "  elif type_code.startswith(\"Ar\"):\n",
        "    type_doc=\"Recueil factice d'imprimés\"\n",
        "  elif type_code.startswith(\"Ba\"):\n",
        "    type_doc=\"Document audiovisuel\"\n",
        "  elif type_code.startswith(\"Bb\"):\n",
        "    type_doc=\"Périodique sous forme de documents audiovisuels\"\n",
        "  elif type_code.startswith(\"Bd\"):\n",
        "    type_doc=\"Collection de documents audiovisuels\"\n",
        "  elif type_code.startswith(\"Br\"):\n",
        "    type_doc=\"Recueil factice de documents audiovisuels\"\n",
        "  elif type_code.startswith(\"Bs\"):\n",
        "    type_doc=\"Extrait de document audiovisuel\"\n",
        "  elif type_code.startswith(\"Fa\"):\n",
        "    type_doc=\"Manuscrit\"\n",
        "  elif type_code.startswith(\"Ga\"):\n",
        "    type_doc=\"Enregistrement sonore musical\"\n",
        "  elif type_code.startswith(\"Gd\"):\n",
        "    type_doc=\"Collection d'enregistrements sonores musicaux\"\n",
        "  elif type_code.startswith(\"Ia\"):\n",
        "    type_doc=\"Image fixe\"\n",
        "  elif type_code.startswith(\"Ir\"):\n",
        "    type_doc=\"Recueil factice d'images fixes\"\n",
        "  elif type_code.startswith(\"Ka\"):\n",
        "    type_doc=\"Carte imprimée\"\n",
        "  elif type_code.startswith(\"Kd\"):\n",
        "    type_doc=\"Collection de cartes imprimées\"\n",
        "  elif type_code.startswith(\"Ke\"):\n",
        "    type_doc=\"Série cartographique\"\n",
        "  elif type_code.startswith(\"La\"):\n",
        "    type_doc=\"Partition manuscrite\"\n",
        "  elif type_code.startswith(\"Ma\"):\n",
        "    type_doc=\"Partition imprimée\"\n",
        "  elif type_code.startswith(\"Md\"):\n",
        "    type_doc=\"Collection de partitions imprimées\"\n",
        "  elif type_code.startswith(\"Mr\"):\n",
        "    type_doc=\"Recueil factice de partitions imprimées\"\n",
        "  elif type_code.startswith(\"Na\"):\n",
        "    type_doc=\"Enregistrement sonore non musical\"\n",
        "  elif type_code.startswith(\"Nb\"):\n",
        "    type_doc=\"Périodique sous forme d'enregistrements sonores non musicaux\"\n",
        "  elif type_code.startswith(\"Nd\"):\n",
        "    type_doc=\"Collection d'enregistrements sonores non musicaux\"\n",
        "  elif type_code.startswith(\"Oa\"):\n",
        "    type_doc=\"Monographie électronique\"\n",
        "  elif type_code.startswith(\"Ob\"):\n",
        "    type_doc=\"Périodique électronique\"\n",
        "  elif type_code.startswith(\"Od\"):\n",
        "    type_doc=\"Collection de documents électroniques\"\n",
        "  elif type_code.startswith(\"Or\"):\n",
        "    type_doc=\"Recueil factice de documents électroniques\"\n",
        "  elif type_code.startswith(\"Os\"):\n",
        "    type_doc=\"\tPartie de document électronique\"\n",
        "  elif type_code.startswith(\"Pa\"):\n",
        "    type_doc=\"\tCarte manuscrite\"\n",
        "  elif type_code.startswith(\"Va\"):\n",
        "    type_doc=\"Objet\"\n",
        "  elif type_code.startswith(\"Za\"):\n",
        "    type_doc=\"Document multimédia multisupport\"\n",
        "  elif type_code.startswith(\"Zb\"):\n",
        "    type_doc=\"Périodique multimédia multisupport\"\n",
        "  elif type_code.startswith(\"Zd\"):\n",
        "    type_doc=\"Collection de documents multimédias multisupports\"\n",
        "  elif type_code.startswith(\"Zr\"):\n",
        "    type_doc=\"Recueil factice de documents multimédias multisupports\"\n",
        "  else :\n",
        "    type_doc=\"Type non renseigné\"\n",
        "\n",
        "  titre=root_item.find('.//datafield[@tag=\"200\"]/subfield[@code=\"a\"]') #On extrait le titre.\n",
        "  titre=titre.text if titre is not None else \"Titre non renseigné\"\n",
        "\n",
        "  auteur=root_item.find('.//datafield[@tag=\"200\"]/subfield[@code=\"f\"]') #On extrait l'auteur.\n",
        "  auteur=auteur.text if auteur is not None else \"Auteur non renseigné\"\n",
        "\n",
        "  if root_item.find('.//datafield[@tag=\"210\"]/subfield[@code=\"c\"]') is not None: #On extrait l'éditeur.\n",
        "    editeur=root_item.find('.//datafield[@tag=\"210\"]/subfield[@code=\"c\"]')\n",
        "  elif root_item.find('.//datafield[@tag=\"214\"]/subfield[@code=\"c\"]') is not None:\n",
        "    editeur=root_item.find('.//datafield[@tag=\"214\"]/subfield[@code=\"c\"]')\n",
        "  else: editeur=None\n",
        "  editeur=editeur.text if editeur is not None else \"Éditeur non renseigné\"\n",
        "\n",
        "  if root_item.find('.//datafield[@tag=\"210\"]/subfield[@code=\"d\"]') is not None: #On extrait la date.\n",
        "    date=root_item.find('.//datafield[@tag=\"210\"]/subfield[@code=\"d\"]')\n",
        "  elif root_item.find('.//datafield[@tag=\"214\"]/subfield[@code=\"d\"]') is not None:\n",
        "    date=root_item.find('.//datafield[@tag=\"214\"]/subfield[@code=\"d\"]')\n",
        "  else: date=None\n",
        "  date=date.text if date is not None else \"Date non renseignée\"\n",
        "  if date:\n",
        "    match=re.search(r\"\\d{4}\", date)\n",
        "    if match:\n",
        "      date= match.group()\n",
        "  else:\n",
        "    date=\"Date non renseignée\"\n",
        "\n",
        "  exemplaire=[]\n",
        "  datafields_316=root_item.findall('.//datafield[@tag=\"316\"]') #On extrait les données d'exemplaire spécifiques au RCR choisi.\n",
        "  for datafield_316 in datafields_316:\n",
        "    subfield_5=datafield_316.find('subfield[@code=\"5\"]')\n",
        "    subfield_a=datafield_316.find('subfield[@code=\"a\"]')\n",
        "    if subfield_5 is not None and subfield_a is not None:\n",
        "      if subfield_5.text.startswith(rcr_input):\n",
        "        exemplaire.append(subfield_a.text.strip())\n",
        "  if not exemplaire :\n",
        "    exemplaire.append(\"Données d'exemplaire non renseignées\")\n",
        "\n",
        "  provenance=[]\n",
        "  datafields_317=root_item.findall('.//datafield[@tag=\"317\"]') #On extrait les données de provenance spécifiques au RCR choisi.\n",
        "  for datafield_317 in datafields_317:\n",
        "    subfield_5=datafield_317.find('subfield[@code=\"5\"]')\n",
        "    subfield_a=datafield_317.find('subfield[@code=\"a\"]')\n",
        "    if subfield_5 is not None and subfield_a is not None:\n",
        "      if subfield_5.text.startswith(rcr_input):\n",
        "        provenance.append(subfield_a.text.strip())\n",
        "  if not provenance :\n",
        "    provenance.append(\"Provenance non renseignée\")\n",
        "\n",
        "  donateur_possesseur=[]\n",
        "  tags_don= [\"702\",\"712\",\"722\"]\n",
        "  code_don=[\"320\",\"390\"]\n",
        "  for tag in tags_don:\n",
        "    for datafield in root_item.findall(f\".//datafield[@tag='{tag}']\"):\n",
        "    #On vérifie si la sous-balise <subfield code=\"4\">320/390</subfield> pour le(s) anciens possesseur(s) / donateur(s) existe.\n",
        "      subfields_4=datafield.findall('subfield[@code=\"4\"]')\n",
        "      if any(subfield_4.text==\"320\" for subfield_4 in subfields_4) or any(subfield_4.text==\"390\" for subfield_4 in subfields_4):\n",
        "        #On récupère les sous-balises d'identification pour le(s) ancien(s) possesseurs(s) / donateur(s).\n",
        "        subfield_a=datafield.find('subfield[@code=\"a\"]')\n",
        "        subfield_b=datafield.find('subfield[@code=\"b\"]')\n",
        "        if subfield_a is not None and subfield_b is not None:\n",
        "            #On ajoute cette identification à la liste des résultats\n",
        "            donateur_possesseur.append((subfield_a.text,subfield_b.text))\n",
        "  if not donateur_possesseur:\n",
        "    donateur_possesseur.append(\"Pas de donateur / possesseur renseigné\")\n",
        "\n",
        "  cote=[]\n",
        "  cote_tags=root_item.findall('.//datafield[@tag=\"930\"]/subfield[@code=\"b\"][.=\"{}\"]/..'.format(rcr_input)) #On extrait les cotes spécifiques au RCR choisi.\n",
        "  for cote_tag in cote_tags :\n",
        "    subfields_a = cote_tag.findall('./subfield[@code=\"a\"]')\n",
        "    for subfield_a in subfields_a:\n",
        "        cote.append(subfield_a.text)\n",
        "\n",
        "  autres_rcr=[]\n",
        "  datafields_930=root_item.findall('.//datafield[@tag=\"930\"]') #On extrait les autres RCR où le document est présent.\n",
        "  for datafield_930 in datafields_930:\n",
        "    subfield_b=datafield_930.find('subfield[@code=\"b\"]')\n",
        "    if subfield_b is not None:\n",
        "      rcr_value=subfield_b.text\n",
        "      if rcr_value!=rcr_input:\n",
        "        autres_rcr.append(rcr_value)\n",
        "\n",
        "\n",
        "  return type_doc,titre,auteur,editeur,date,exemplaire,provenance,donateur_possesseur,cote,autres_rcr"
      ],
      "metadata": {
        "id": "pcWmFDowjunZ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Application à la liste de PPN pour obtenir le *dataframe* détaillé"
      ],
      "metadata": {
        "id": "bpL6-Gh61WCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data={\"PPN\": [],\"Type de document\": [],\"Titre\": [],\"Auteurs\": [],\"Éditeur\": [],\"Date\": [],\"Données d'exemplaire\":[],\"Provenance\": [], \"Donateur / possesseur\":[],\"Cote\": [], \"Autres localisations Sudoc\":[]}\n",
        "for ppn in liste_ppn:\n",
        "        item_info=get_item(ppn)\n",
        "        data[\"PPN\"].append(ppn)\n",
        "        data[\"Type de document\"].append(item_info[0])\n",
        "        data[\"Titre\"].append(item_info[1])\n",
        "        data[\"Auteurs\"].append(item_info[2])\n",
        "        data[\"Éditeur\"].append(item_info[3])\n",
        "        data[\"Date\"].append(item_info[4])\n",
        "        data[\"Données d'exemplaire\"].append(item_info[5])\n",
        "        data[\"Provenance\"].append(item_info[6])\n",
        "        data[\"Donateur / possesseur\"].append(item_info[7])\n",
        "        data[\"Cote\"].append(item_info[8])\n",
        "        data[\"Autres localisations Sudoc\"].append(item_info[9])\n",
        "df_don=pd.DataFrame(data)\n",
        "df_don"
      ],
      "metadata": {
        "id": "ge9MjyEs8vIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rcr_autres=df_don[\"Autres localisations Sudoc\"].explode() #On convertit la liste des numéros des autres RCR où le document est présent en liste des noms de RCR.\n",
        "rcr_autres=rcr_autres.drop_duplicates()\n",
        "rcr_autres=rcr_autres.dropna()\n",
        "rcr_autres=rcr_autres.to_list()\n",
        "liste_rcr_autres=[]\n",
        "for rcr in rcr_autres:\n",
        "  rows=df_rcr[df_rcr[\"RCR\"]==rcr]\n",
        "  if not rows.empty:\n",
        "        liste_rcr_autres.extend(rows[\"LIBELLE\"].tolist())\n",
        "liste_rcr_autres.sort()\n",
        "liste_rcr_autres"
      ],
      "metadata": {
        "id": "se8-xwVtm_Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(liste_rcr_autres) #On voit dans combien d'autres RCR il y a des documents du fonds analysé."
      ],
      "metadata": {
        "id": "2FvRPlAdjKSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_unica=len(df_don[df_don[\"Autres localisations Sudoc\"].apply(lambda x:len(x)==0)]) #On compte le nombre d'unica dans le Sudoc présents dans le fonds analysé (en comptant le nombre d'éléments pour lesquels il n'y a pas d'autres localisations dans le Sudoc).\n",
        "print(nb_unica)\n",
        "pourcentage_unica=round((len(df_don[df_don[\"Autres localisations Sudoc\"].apply(lambda x:len(x)==0)])/len(liste_ppn)) * 100,2) #On calcule le pourcentage d'unica.\n",
        "pourcentage_unica"
      ],
      "metadata": {
        "id": "MoM73-61okog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Export historicisé du *dataframe*"
      ],
      "metadata": {
        "id": "IskMp3OKCkBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aujourdhui=datetime.now().strftime(\"%Y%m%d\") #On exporte les données du fonds analysé en csv historicisé.\n",
        "nom_fichier=f\"{aujourdhui}_export_notices_don_{rpc_input}_RCR{rcr_input}.csv\"\n",
        "df_don.to_csv(nom_fichier,index=True,encoding=\"utf-8\")"
      ],
      "metadata": {
        "id": "IeZJ2a8qCoOf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}